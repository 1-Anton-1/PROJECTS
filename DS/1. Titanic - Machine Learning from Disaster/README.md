# 1. Titanic - Machine Learning from Disaster

## Цель:

Для моей первой задачи из области DS - наглядно увидеть на практике работу ML на несложных данных, сделав предсказание о виживаемости пассажиров. 

## Описание:

По имеющимся данным о пассажирах предсказать выживут ли они или нет.

### Исходные данные [источник](https://www.kaggle.com/competitions/titanic):
	
`train` - тренировочный датафрейм, содержащий данные о пассажирах и целевую колонку "Survived" (выжил).

`test` - тестовый датафрейм, содержащий те же колонки что и `train`, но без целевой колонки "Survived".

Описание колонок датафреймов `train` и `test`:

* PassengerId - ID пассажиров (1-891)
* Survived - целевая колонка, выжил (1) пассажир или нет (0)
* Pclass - класс пассажира от 1 до 3
* Name - полное имя пассажира
* Sex - пол 
* Age - возраст
* SibSp - это число братьев, сестер или супругов на борту у человека
* Parch - количество родителей или детей, с которыми путешествовал пассажир
* Ticket - номер билета
* Fare - тариф билета
* Cabin - номер каюты
* Embarked - порт посадки пассажира
		 

### В чем состоит решение задачи?

Просматриваем данные, делаем предобработку/аггрегацию данных (приводим их к виду, удобному для машинного обучения).
Создаем модель, обучаем модель, смотрим на предсказательную точность (predict()). Варьируем параметры модели, так чтобы точность становилась как можно выше.
Модель с оптимальными параметрами прогоняем через тестовую выборку и выводим предсказания в отдельный файл.

#### Описание имплементация задачи:

1. Импортируем библиотеки и считываем данные из input-датафрейма (`train.csv`).
2. Производим первичный анализ имеющихся данных (визуальный просмотр фичей (колонок) и выведение общих показателей таких как количество утерянных значений (NaN) в имеющихся данных).
3. Сделаем предобработку данныx:
   	* выделим целевую колонку в y, а остальные столбцы в датасет X;
   	* преобразуем строковые переменные датасета X в номинативные, применив метод pd.get_dummies(X);
   	* заменим NaN значения в колонке Age на медианное значение;
   	* сделаем сплит каждого из датасетов X и y на тренировочный и тестовый наборы в соотношении 2:1 соотвественно. Таким образом получим датасеты X_train, X_test, y_train, y_test.
4. Инициализируем экземпляр класса RandomForestClassifier ("случайный лес"), задав параметры количество эстимейторов ("число деревьев") и глубину разбиений. Тем самым создадим ML-модель.
5. Сделаем fit нашей модели (обучим на тренировочных данных (т. е. покажем нашей модели данные (значения колонок тренировочного датасета X_train ("фичи")), по которым мы ходим делать предсказания и для каждого набора данных дадим правильные ответы (колонка y_train)).
6. Посчитаем точность предсказания нашей модели на данных (сделаем скор на X_test, y_test).
7. Прочитаем данные из input-датафрейма (`test.csv`) и сделаем аналогичную предобработку данных см. п. 3 (кроме последнего подпункта)
8. Сделаем предсказание на тестовой выборке данных (сделаем предикт)
9. Запишем предсказания в `submission.csv` файл.

## Итоги
Не смотря на то, что предсказательная точноть получилась не столь велика (82% на тренировочных данных и 77,5% на тестовых данных) - удалось наглядно увидеть на практике работу ML, в частности модели из класса решающих деревьев.

