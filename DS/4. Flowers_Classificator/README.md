# 4. Flowers_Classificator

## Цель:

Создать модель, предсказывающую на основе данных о животных, то как быстро этих животных заберут из приюта. 

## Описание:

Миллионы бездомных животных ежедневно страдают на улицах или подвергаются эвтаназии в приютах по всему миру. Если для них будет найден дом, можно будет спасти много драгоценных жизней и создать больше счастливых семей. Платформа PetFinder.my разрабатывает инструмент на основе ИИ, который оценивает насколько милыми являются питомцы на основании метаданных о них. В этой задаче необходимо разработать алгоритм прогнозирования возможности "усыновления" домашних животных (как быстро будет "усыновлено" то или иное животное).  

### Исходные данные [источник](https://www.kaggle.com/competitions/petfinder-adoption-prediction):
	
`train.csv` - тренировочный датафрейм, содержащий данные о питомцах

`test.csv` - тестовый датафрейм, содержащий те же колонки, что и `train`, но без целевой колонки "AdoptionSpeed". 

Описание колонок датафреймов `train` и `test`:
+ **PetID** — уникальный хеш-идентификатор профиля питомца.
+ **AdoptionSpeed**  ​​— как быстро животное забрали из приюта после размещения информации о нем на платформе.
+ **Type**  – Тип животного (1 = Собака, 2 = Кошка)
+ **Name**  — имя домашнего животного (пусто, если не указано имя).
+ **Age** – возраст животного, если оно указано в списке, в месяцах.
+ **Breed1**, **Breed2** – основная и дополнительная породы домашнего животного.
+ **Gender**  — пол животного (1 = самец, 2 = самка, 3 = смешанный, если в профиле представлена ​​группа питомцев).
+ **Color1**, **Color2**, **Color3** – градация цвета 1 питомца по внутреннему словарю платформы.
+ **MaturitySize**  — размер животного (1 = маленький, 2 = средний, 3 = большой, 4 = очень большой, 0 = не указано)
+ **FurLength**  — длина меха (1 = короткий, 2 = средний, 3 = длинный, 0 = не указано)
+ **Vaccinated**  – животное вакцинировано (1 = Да, 2 = Нет, 3 = Не уверен)
+ **Dewormed**  — домашнее животное прошло дегельминтизацию (1 = Да, 2 = Нет, 3 = Не уверен)
+ **Sterilized**  – животное стерилизовано/кастрировано (1 = Да, 2 = Нет, 3 = Не уверен)
+ **Health**  — состояние здоровья (1 = здоров, 2 = незначительная травма, 3 = серьёзная травма, 0 = не указано)
+ **Quantity**  - количество питомцев, представленных в профиле.
+ **Fee** – плата за "усыновление" животного (0 = бесплатно)
+ **State**  — расположение штата в Малайзии, значение согласно внутреннему словарю.
+ **RescuerID**  - уникальный хеш-идентификатор спасателя.
+ **VideoAmt** – общее количество загруженных видео для этого питомца.
+ **PhotoAmt** – общее количество загруженных фотографий этого питомца.
+ **Description** — описание профиля этого питомца. Основной используемый язык — английский, некоторые — малайский или китайский.

### В чем состоит решение задачи?

Задачу можно решать как задачу классификации, так и как задачу регрессии. В данном случае создаем модель, решающую задачу классфикации.
Просматриваем данные и делаем их предобработку. Выделяем главные признаки, по которым приоритетно делать классификацию животных по времени их "усыновления". Применяем модель решающих деревьев для изначального датасета данных о животных. Делаем выводы о возможных причинах невысокой точности модели. Принимаем во внимание главную фичу, которая оказывает сильное влияние на нашу целевую переменную - фото-аватар на платформе. Конвертируем фото в векторы и применяем метод главных компонент (PCA) для понижения размерности векторов с 1000 до 6. Используем модель градиентного спуска для измененного датасета и делаем предсказание на тестовом наборе данных.   

### Краткое описание имплементации задачи:

1. Импортируем библиотеки и считываем данные из input-датафрейма (`train.csv`).
2. Изучим имеющиеся данные, приведем к корректному типу некоторые значения колонок. Выделим главные фичи, с которыми коррелирует наша целевая переменная (здоровье, возраст, внешний вид, привито/не привито).
3. Удаляем лишние фичи, которые не оказывают сколько-нибудь значимого влияния на целевой показатель.
4. Делим тренировочные данные на тренировочный и тестовые датасеты.
5. Создадим функцию-pipeline для прогонки всех наших будущих моделей.
6. Отбрасываем неподходящие типы моделей. Так например, применять k-NN классификатор (метод ближайших соседей) здесь не корренктно, так как в наших данных много категориальных данных.
7. Посмотрим на предсказательную точность, применив модель RandomForestClassifier. Точность при n_estimators=25, n_jobs=4 получился score около 0,27.
8. В двух предыдущих подходах, мы не учитывали влияние такой важной фичи как фото животного! И самым главным является первое фото животного, то которое в первую очередь видят пользователи.
9. Проверяем наличие фото у животных и приводим их все к одному виду с помощью .convert('RGB').
10. Создаем матрицу эмбеддингов, переведя картинки в векторный вид. Присоединяем матрицу векторов к нашему исходному датафрейму.
11. Применив метод RandomForest на 1019 фичах, получаем низкие результаты. Так как слишком много фичей!
12. Чтобы снизить  размерность данных используем метод главных компонент и понизим размерность эмбеддинговых фичей с 1000 до 6.
13. Приджойним "сжатые картинки" к нашему датасету из 19 фичей (изначальный датасет).
14. Посмотрим на score модели-экземпляра класса RandomForestClassifier. Score увеличился на несколько процентов!
15. Импортируем CatBoostClassifier и обучим модель catboost на подготовленных данных. Посмотрим на score и сделаем предсказания на тестовом датасете. 


## Итоги:
Для решения данной задачи поочередно были применены подходы построения случайных деревьев и градиентного бустинга (RandomForestClassifier и CatBoostClassifier). Наибольшая точность на тестовом датасете данных получилась на моделе CatBoostClassifier (score=0.28). Как вариант возможного улучшения точности в решении данной задачи вижу применение моделей регрессии.
